[{"authors":["admin"],"categories":null,"content":"Ich beschäftige mich mit der Planung und Umsetzung von KI Use-Cases und dem Versuch, zukünftige Psychologen für Statistik und R zu begeistern.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"de","lastmod":1731257707,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://max-bre.de/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Ich beschäftige mich mit der Planung und Umsetzung von KI Use-Cases und dem Versuch, zukünftige Psychologen für Statistik und R zu begeistern.","tags":null,"title":"Max Brede","type":"authors"},{"authors":null,"categories":null,"content":" SetFit Multilingual Inference Example This tutorial demonstrates how to use a pretrained SetFit model for multilingual text classification inference.\nThe script works on Windows, macOS, and Linux, and can be run using Python (via Anaconda or venv) or R with the reticulate package.\nExample Python Code Here’s how to load the pretrained model and make predictions:\nfrom setfit import SetFitModel model = SetFitModel.from_pretrained( \u0026quot;\u0026lt;model-path\u0026gt;\u0026quot; ) model.predict_proba( [ \u0026quot;Du schaffst das schon.\u0026quot;, \u0026quot;Tu vas y arriver.\u0026quot;, \u0026quot;Zvládnete.\u0026quot;, \u0026quot;You\u0026#39;ll manage.\u0026quot;, \u0026quot;Te las arreglarás.\u0026quot;, \u0026quot;Saate hakkama.\u0026quot; ] )  Setup and Run (Python) Option 1: Using venv (cross-platform) # Create and activate virtual environment python -m venv venv source venv/bin/activate # macOS/Linux venv\\Scripts\\activate # Windows # Upgrade pip and install dependencies pip install --upgrade pip pip install setfit Then run the script:\npython your_script.py  Option 2: Using Anaconda # Create new environment conda create -n setfit_env python=3.10 -y conda activate setfit_env # Install pip and dependencies pip install --upgrade pip pip install setfit Run your script:\npython your_script.py   Running in R with Reticulate You can use the reticulate package to run the Python model directly from R.\nNote: You may need to install conda or virtualenv support explicitly using reticulate::install_miniconda() or by ensuring virtualenv is available on your system.\n1. Install Required Packages In R:\ninstall.packages(\u0026quot;reticulate\u0026quot;)  2. Set Up Python Environment You can use either of the following options:\nConda library(reticulate) install_miniconda() # Only needed if conda is not yet installed conda_create(\u0026quot;setfit_env\u0026quot;, packages = \u0026quot;python=3.10\u0026quot;) use_condaenv(\u0026quot;setfit_env\u0026quot;, required = TRUE) py_install(\u0026quot;setfit\u0026quot;, envname = \u0026quot;setfit_env\u0026quot;, method = \u0026quot;pip\u0026quot;)  venv (Alternative) library(reticulate) virtualenv_create(\u0026quot;setfit_env\u0026quot;) use_virtualenv(\u0026quot;setfit_env\u0026quot;, required = TRUE) py_install(\u0026quot;setfit\u0026quot;, envname = \u0026quot;setfit_env\u0026quot;, method = \u0026quot;pip\u0026quot;)   3. Run Python Code in R library(reticulate) # Use the environment use_condaenv(\u0026quot;setfit_env\u0026quot;, required = TRUE) # Import setfit setfit \u0026lt;- import(\u0026quot;setfit\u0026quot;) # Load the model model \u0026lt;- setfit$SetFitModel$from_pretrained(\u0026quot;\u0026lt;redacted for anonymous submission\u0026gt;/amc_setfit\u0026quot;) # Predict texts \u0026lt;- c( \u0026quot;Du schaffst das schon.\u0026quot;, \u0026quot;Tu vas y arriver.\u0026quot;, \u0026quot;Zvládnete.\u0026quot;, \u0026quot;You\u0026#39;ll manage.\u0026quot;, \u0026quot;Te las arreglarás.\u0026quot;, \u0026quot;Saate hakkama.\u0026quot; ) probs \u0026lt;- model$predict_proba(texts) print(probs)    ","date":1742860800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1742860800,"objectID":"f79636523967278c08f112161274c87b","permalink":"https://max-bre.de/blog/using_the_amc/","publishdate":"2025-03-25T00:00:00Z","relpermalink":"/blog/using_the_amc/","section":"blog","summary":"SetFit Multilingual Inference Example This tutorial demonstrates how to use a pretrained SetFit model for multilingual text classification inference.","tags":["Machine Learning","Implicit motives","NLP"],"title":"Using the AMC","type":"blog"},{"authors":null,"categories":null,"content":" Das (noch wachsende) Skript zu meiner im WS 24 zusammen mit Alwin Klick gehaltenen Veranstaltung zu Grundlagen und Anwendungen von generativer KI an der FH Kiel.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript/die App auch hier gefunden werden.\n","date":1731196800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731196800,"objectID":"11a386c3e0080b28f94de52c10517f0a","permalink":"https://max-bre.de/skripte/generative_ai/","publishdate":"2024-11-10T00:00:00Z","relpermalink":"/skripte/generative_ai/","section":"skripte","summary":"Das (noch wachsende) Skript zu meiner im WS 24 zusammen mit Alwin Klick gehaltenen Veranstaltung zu Grundlagen und Anwendungen von generativer KI an der FH Kiel.","tags":["Python","AI"],"title":"Elective Module 'Generative AI'","type":"skripte"},{"authors":null,"categories":null,"content":" Das Skript zu meinem Teil des vom 19.-22.02.2024 am KFN veranstalteten Workshops zu Grundlagen und Anwendungen von R im Rahmen des KFN-MethodLabs. Das Skript gibt eine grobe Einführung in R um dann einen Einstieg in Auswertungen mit dem tidyverse und tidymodels zu geben. Am Ende werden quarto und Möglichkeiten zur Ergebniszusammenstellung eingeführt. Da mein Teil sich auf 2 Tage beschränkte, sind die Themen nicht in der Tiefe behandelt, die ihnen gebührt - eher ein Überblick um die Möglichkeiten von statistischen Auswertungen mit tidy-Frameworks zu geben.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript/die App auch hier gefunden werden.\n","date":1708300800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1708300800,"objectID":"eaaf6d161c87daf5aaa80b164ce7739b","permalink":"https://max-bre.de/skripte/crash2/","publishdate":"2024-02-19T00:00:00Z","relpermalink":"/skripte/crash2/","section":"skripte","summary":"Das Skript zu meinem Teil des vom 19.-22.02.2024 am KFN veranstalteten Workshops zu Grundlagen und Anwendungen von R im Rahmen des KFN-MethodLabs.","tags":["R","Data Wrangling","Data Viz","Statistik"],"title":"R Crashkurs - KFN-Methodlabs","type":"skripte"},{"authors":null,"categories":null,"content":" Das Skript bietet eine Sammlung an Tipps zu 1. der Literaturrecherche - zum Suchen, Sammeln und Lesen von (psychologischen) Arbeiten und 2. der Erstellung einer Thesis mit R - vom Einlesen von vielen Experimentellen Ergebnissen über die Erstellung von Grafiken und Tabellen zum Verfassen mit Quarto\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript/die App auch hier gefunden werden.\n","date":1699401600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"c51f23aa28533f70b45a0a45e03ade18","permalink":"https://max-bre.de/skripte/thesisr/","publishdate":"2023-11-08T00:00:00Z","relpermalink":"/skripte/thesisr/","section":"skripte","summary":"Das Skript bietet eine Sammlung an Tipps zu 1. der Literaturrecherche - zum Suchen, Sammeln und Lesen von (psychologischen) Arbeiten und 2.","tags":["Academia","Crossref","Literaturrecherche","R","Quarto","Data Wrangling","Data Viz"],"title":"Vorschläge zur Thesis-Bearbeitung","type":"skripte"},{"authors":["Max Brede","Athanasios Mazarakis","Isabella Peters"],"categories":null,"content":"","date":1696809600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"6cffd873b909f59cc41c84c4e49406f9","permalink":"https://max-bre.de/publication/2023_brede_whatdrivesresearchers/","publishdate":"2023-10-09T00:00:00Z","relpermalink":"/publication/2023_brede_whatdrivesresearchers/","section":"publication","summary":"External science communication uses media and other means, such as news reports on scientific publications, to produce awareness and understanding of science and its results. Scientific publications that were featured in the news are linked to higher citations and altmetric-counts when compared to similar unfeatured articles. So far, the question about the relationship between attributes of scientific publications, their mentions in a news report, and their effect on researchers' decision to look up a scientific publication remained unanswered: a research gap this study attempts to fill. First, we conducted a threephased variation of a Delphi survey to generate a selection of attributes that experts deem relevant for evaluating scientific publications. Then the attributes were discussed with a focus group and optimized for a large-scale online conjoint study with 642 respondents. Statistical analysis revealed that attributes which indicate expert opinion and methodological quality are the major drivers behind looking up scientific publications mentioned in news reports. This finding underscores that forms of external science communication and the highlighting of particular publication attributes positively affect the awareness of scientific publications that are also positively related with a publication's citation counts.","tags":null,"title":"4. What drives researchers to look up research publications they found in the news?","type":"publication"},{"authors":null,"categories":null,"content":"git und die darauf basierenden Hosting-Services Github und Gitlab sind Tools zur Versionskontrolle, die im Entwicklungskontext den De-Facto Industriestandard darstellen. Der Grund für diesen Erfolg ist dabei die Baum-artige Struktur in der Änderungen am Code-Stamm getracked und nachvollzogen werden können. Über verschiedene \u0026ldquo;branches\u0026rdquo; können außerdem Änderungen gebaut, erweitert und getestet werden, bevor sie in den zentralen Codestamm (bei Github der \u0026ldquo;main\u0026rdquo;-branch) \u0026ldquo;gemerged\u0026rdquo; werden. Dabei ist es generell möglich, Änderungen in allen möglichen Dateiformaten zu tracken, so richtig sinnvoll sind Änderungen und Änderungsabschnitte aber vor allem in Klartextformaten ohne Serialisierung verständlich. Textfiles müssen aber ja nicht notwendigerweise nur Code enthalten. Mit der wachsenden Beliebtheit von Rmarkdown und neuerdings Quarto geht (zumindest in der R-Community) der Trend zum Verfassen von Texten in auf markdown basierenden Formaten, die mit Hilfe von Pandoc in andere Formate kompiliert werden können. Da diese Formate in einfachen Textfiles abgespeichert werden, können so die Vorteile von git zum Tragen kommen. Ein workflow zum gemeinsamen Erstellen von Texten wie er zum Beispiel beim Schreiben gemeinsamer Publikationen nötig ist, gestützt auf eins der populären markdown Formate und git, könnte eine echte Alternative zur Co-Autorenschaft in Word sein. Dabei hat der vorgeschlagene Workflow die folgenden Vorteile:\n Quarto/Rmarkdown1 haben auch ohne Kombination mit git Vorteile beim Erstellen und Einbinden von Grafiken, Tabellen und statistischen Ergebnissen mit git kommt ein Versionsmanagement dazu, dass Änderungen verfolgbar und auch zurückziehbar macht, ohne dass die Festplatte voll von manuskript_final_v1_v3.docx etc. wird die gesamte Änderungsgeschichte ließe sich publizieren, was aus Gesichtspunkten offener Wissenschaft attraktiv sein kann. Muss aber nicht. mit Github/Gitlab Issues kommt ein ganzer Stack an Projektmanagement-Tools dazu, der optional genutzt werden kann mit Github/Gitlab Action lassen sich Tests und Updates vor oder beim Commit automatisieren das Zusammenarbeiten über Betriebssystem-Grenzen hinweg ist problemlos. Kein Ärger mehr mit verschiedenen Office-Versionen oder Formatierungskonflikten zwischen MS Office und Open Scource Lösungen  Dabei sind die Nachteile relativ gering - Quarto ist sehr weit gekommen und unterstützt alle Standard-Anforderungen an akademische Arbeiten - Zitieren, Formatieren und das Nutzen von Latex-Templates ist kein Problem. Dazu kommt dass zumindest bei der Nutzung von RStudio seit kurzem auch eine WYSIWYG-Lösung zur Texteditirung dazugekommen ist - die Bedienung des Visual Editors sollte Leuten, die an Word gewöhnt sind, keine so große Herausforderunge mehr bereiten wie das Schreiben in reinem markdown. Der einzige größere Nachteil ist, dass sich der Ablauf zum Kommentieren ändert - dazu kommen wir aber später.\nEinrichtung Unter Mac und Unix-Distros ist git vorinstalliert, unter Windows muss der Client noch installiert werden: Download git\nUm Änderungen darzustellen gibt es zwar auch Funktionalität in RStudio, die github Desktop-GUI ist aber auch ganz schick: Download github Desktop\nRstudio als IDE bietet sich an, hier wird aber davon ausgegangen, dass die Installation bereits passiert ist. Außerdem ist zum Einbinden von Zitationen in Quarto-Texten eine Zotero-Installation mit dem Better Bibtex Addon zu empfehlen. Im visuellen Editor gibt es einen eigenständigen Zitationsmanger mit Zotero-Connection, im Source-Editor habe ich aber bessere Erfahrungen mit dem citr-Paket gemacht, das es leider nicht mehr auf Cran aber noch auf github gibt. Zum Schreiben mit Rmarkdown oder der Erweiterung Bookdwon braucht es nur die entsprechenden R-Pakete, für Quarto is nocht eine eigenständige Quarto-Installation nötig. Die ist hier zu finden.\nZuletzt wird ein Github-Repo2 benötigt.\nZur Einrichtung braucht es erst einen Github-Account, der Rest kann über die Github-Desktop-GUI erledigt werden. Nach der Anmeldung in der GUI kann dafür einfach wie in Figure 1 zu sehen auf File -\u0026gt; New repository geklickt oder Strg + N gedrückt werden.\n Figure 1: Repo erstellen  Im sich daraufhin öffnenden Dialog (Figure 2) kann das zu erstellende Repo eingerichtet werden. Neben Name, Beschreibung und lokalem Speicherort kann hier auch eine Lizenz und ein gitignore-Vorbild angegeben werden. Das gitignore-File gibt an, welche Dateien grundsätzlich nicht ins Repo aufgenommen werden sollen - für Projekte wie hier beschrieben bietet sich hier das R-Template an. Außerdem\n Figure 2: Einstellungen bei Repoerstellung  Nach der lokalen Erstellung muss das Repo noch mit einem Github-remote verknüpft werden. Das kann einfach mit \u0026ldquo;Publish Repository\u0026rdquo; (Figure 3) geschehen, solange noch kein Repo mit dem entsprechenden Namen existiert.\n Figure 3: Erstellung des Github-Repos  Wenn sich nun in Github Web angemeldet wird, müsste das neue repository in der Liste auftauchen. Nach der o.g. Erstellung können im Repo unter den Einstellungen -\u0026gt; Collaborators noch Coautoren eingeladen werden.\nAls Vorbereitung des Erstellens von Issues für Kommentare kann dem Repo noch die TODO to Issue Action hinzugefügt werden. Diese legt automatisch Issues an, wenn in einem Textfile ein TODO-Kommentar angelegt ist. Zum Einbinden in das Repo muss im Repo ein Ordner namens .github und darin einer namens workflows angelegt werden. In diesem workflows-Ordner wird dann ein YAML file mit dem Namen TODO.yml angelegt, das den folgenden Inhalt enthält:\nname: \u0026#34;Run TODO to Issue\u0026#34; on: [\u0026#34;push\u0026#34;] jobs: build: runs-on: \u0026#34;ubuntu-latest\u0026#34; steps: - uses: \u0026#34;actions/checkout@v3\u0026#34; - name: \u0026#34;TODO to Issue\u0026#34; uses: \u0026#34;alstr/todo-to-issue-action@v4\u0026#34; with: AUTO_ASSIGN: true #Ersteller zuweisen wenn nicht anders angegeben IDENTIFIERS: \u0026#39;[{\u0026#34;name\u0026#34;: \u0026#34;COMMENT\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;comment\u0026#34;]}, {\u0026#34;name\u0026#34;: \u0026#34;SUGGESTION\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;suggestion\u0026#34;]}]\u0026#39; # Liste mit Standard-Issue-Tags Damit die Action läuft muss die Änderung noch ins Repo gepushed werden. Dazu einmal in Github Dektop committen (Figure 4) und dann pushen (Figure 5).\n Figure 4: Änderungen Committen   Figure 5: Änderungen Pushen  Schreiben Um einen Artikel zu schreiben bietet sich an, entweder bookdown oder quarto zu nutzen. Beide unterstützen das Schreiben eines Übergeordneten Dokuments in einer Reihe von anderen Dokumenten, zum Beispiel aufgesplittet nach Kapiteln. Das Aufteilen ist nicht unbedingt nötig, kann aber das Zusammenarbeiten vereinfachen.\nDas Arbeiten mit einem Quarto-Stack hat außerdem den Vorteil, dass Auswertung, Poster, Paper und Präsentation in einem Abwasch erledigt werden können und alles an einer Stelle gesammelt vorliegt.\nEin _quarto.yml, das Zweck genutzt wird, könnte wie folgt aussehen:\nproject: output-dir: _output render: - _quarto/paper.qmd toc: false number-sections: false bibliography: references.bib csl: _quarto/apa.csl title: Testartikel format: html: theme: cosmo pdf: documentclass: scrreprt Der Text kann dann einfach in den einzelnen Textfiles runter geschrieben werden. Wenn mehrere Kapitel in einem Dokument eingebunden werden sollen, kann die includes-Syntax von Quarto genutzt werden. Der Ordner mit den Quarto-Files wurde in diesem Beispiel mit einem Unterstrich eingeleitet, damit beim Rendern nicht automatisch für jedes File ein Output generiert wird.\nFormatierung in Quarto Quarto bietet vielfältige Formatierungsoptionen, um das Aussehen von Texten und Grafiken anzupassen. Die offizielle Dokumentation enthält ausführliche Informationen und Beispiele zur Formatierung für verschiedene Output-Formate.\nTabellen und Grafiken können außerdem direkt in R oder Python Codechunks erstellt und eingebunden werden, Beispiele für gute Pakete zur Formatierung von Tabellen in R sind huxtable und kableExtra.\nFür Grafiken führt in R natürlich kein Weg an ggplot vorbei, für Python ist seaborn eine gute Anlaufstelle.\nGrafiken und Tabellen können dann über die Chunk-Optionen in Quarto beschriftet werden und über die in der Dokumentation beschriebenen Syntax Cross-referenziert werden. Mögliche Chunk-Optionen sind in der knitr-Referenz aufgelistet.\nZitate in Quarto Zotero bietet in Kombination mit dem citr-Paket und Better BibTeX eine hervorragende Möglichkeit, Literaturverweise in Quarto-Dokumenten zu verwalten. Nach der Installation von Zotero und Better BibTeX kann entweder direkt über citr auf die Zotero Bibliothek (siehe die citr-Dokumentation oder auf ein aus Zotero exportiertes .bib-file zugegriffen werden. Im Quarto-Dokument kann dann auf Referenzen verwiesen werden, indem der folgende Passus in den _quarto.yml YAML-Header eingefügt wird:\nbibliography: references.bib csl: quarto/apa.csl Über Addins -\u0026gt; CITR Insert citation kann die jeweilige Bibliothek durchsucht und die Referenz eingefügt werden. Wenn aus der Zotero-Bibliothek referenziert wird, wird das references.bib-File automatisch ergänzt. Beim Rendern des Dokuments wird die Literatursammlung im unter cls im header angegebenen Format automatisch am Ende des Dokuments oder an der mit dem folgenden Inhalt angegebenen Stelle eingefügt:\n::: {#refs} ::: Format-Vorlagen auf Quarto-Dokumente anwenden Quarto unterstützt die Verwendung von Format-Vorlagen, um das Design von Dokumenten anzupassen. Um z.B. eine LaTeX-Vorlage (wie zum Beispiel von einem Journal ausgegeben) auf ein Quarto-Dokument anzuwenden, müssen die folgenden Zeilen in den YAML-Header des Quarto-Dokuments eingefügt werden:\nformat: pdf: documentclass: my-template includes: in_header: my-template.tex Weitere Informationen zum Anpassen von PDF-Dokumenten mit Quarto- und LaTeX-Vorlagen sind in der Quarto-Dokumentation zu finden.\nZusammenarbeit Kommentieren Dank der TODO to Issue Action werden Inline-Kommentare in den Quarto- oder R Markdown-Dateien direkt in GitHub Issues umgewandelt. Dies ist besonders nützlich, um Feedback oder Anmerkungen während des Schreibprozesses zu geben und vor allem Anmerkungen direkt diskutieren zu können. Um dieses Feature zu nutzen, müssen Kommentare zu einem Textabschnitt wie folgt direkt in das qmd-file geschrieben werden:\n Kommentare sollten mit TODO, COMMENT oder SUGGESTION beginnen und können in HTML- oder R-Kommentaren platziert werden. Hinter die Anmerkungsart muss in Klammern der github-tag des Kommentar-Autors genannt werden. Ein Kommentar könnte zum Beispiel so aussehen:  \u0026lt;!-- TODO(MBrede): Die Grafik könnte mehr Farbe vertragen.--\u0026gt;  Mit \u0026ldquo;assignees:\u0026rdquo; kann eine Liste von Projektmitarbeitern angegeben werdne, die im Issue eingebunden und damit per Mail informiert werden soll:  \u0026lt;!-- TODO(MBrede): Die Grafik könnte mehr Farbe vertragen. assignees: MBrede, vlerche--\u0026gt;  Mit \u0026ldquo;labels:\u0026rdquo; können außerdem direkt Tags für das Issue angegeben werden:  \u0026lt;!-- TODO(MBrede): Die Grafik könnte mehr Farbe vertragen. assignees: MBrede, vlerche labels: ggplot2--\u0026gt; Kleinere Änderungen können natürlich direkt im file umgesetzt werden. Bei größeren Umformulierungsvorschlag ist ein Beispiel im Kommentar aber eine einfachere Option, auch wenn einzelne vorgeschlagene Änderungen ausgewählt werden können.\nNach Durchgehen eines Files müssen die Änderungen ins repo zurückgespielt werden. Dazu einmal über die Github-GUI Committen mit einer möglichst beschreibenden Änderungszusammenfassung und über die Schaltfläche oben rechts Pushen.\nDie TODO to Issue Action erstellt automatisch ein neues Issue für jeden Kommentar. Issues werden mit den entsprechenden Labels versehen, die in der .github/workflows/TODO.yml-Datei definiert und im Kommentar angegeben sind.\nWenn ein Issue erstellt wurde, kann das Issue diskutiert, bearbeitet und geschlossen werden, sobald es gelöst ist. Bei Entfernen des Kommentars wird das Issue auch direkt als geschlossen markiert.\nPush/Pull-Workflow Um Überblick über die Änderungshistorie zu behalten und die aktuellste Version von gerade in Bearbeitung befindlichen Abschnitten zu trennen, bietet GitHub den Pull-Request-Workflow:\n Jeder Autor erstellt einen neuen Branch für seine Änderungen. Nachdem die Änderungen vorgenommen wurden, erstellt der Autor einen Pull Request. optional können andere Autoren auf Wunsch die Änderungen überprüfen und Feedback geben und abschließend Pull Request genehmigen. Beim Erstellen des Pull-Requests kann ein Co-Autor getagged und damit benachrichtigt werden. Wenn alle Autoren (oder der/die Erst-Autor:in) mit den Änderungen einverstanden sind, wird der Pull Request in den Haupt-Branch gemerged.  Cherry-Picking und Blaming von Änderungen Im gemeinsamen Schreibprozess kann es hilfreich sein, bestimmte Änderungen aus einem Branch in einen anderen zu übernehmen oder herauszufinden, wer eine bestimmte Änderung vorgenommen hat. Hier sind zwei nützliche Funktionen, die dabei helfen: Cherry-Picking und Blaming.\nCherry-Picking Mit Cherry-Picking können gezielt einzelne Commits aus einem Branch in einen anderen übernommen werden. Dies ist besonders nützlich, wenn nur bestimmte Änderungen aus einem Branch genutzt werden sollen, ohne den gesamten Branch zu mergen. Die folgenden Schritte beschreiben, wie Cherry-Picking verwendet wird:\n  Zunächst muss sichergestellt werden, dass man sich auf dem gewünschten Ziel-Branch befindet, in den der Commit übernommen werden soll. Um den aktuellen Branch im Terminal zu überprüfen, kann der Befehl git branch verwendet werden. Der aktuelle Branch wird dabei mit einem Sternchen (*) gekennzeichnet.\n  Sollte der aktuelle Branch nicht der gewünschte Ziel-Branch sein, kann man mit dem Befehl git checkout  auf den richtigen Branch wechseln, wobei  durch den tatsächlichen Namen des gewünschten Ziel-Branches ersetzt wird.\n  Die Commit-ID des gewünschten Commits muss gefunden werden. Dies kann durch das Durchsuchen der Commit-Historie in GitHub Desktop oder auf der GitHub-Webseite erfolgen.\n  Ein Terminal wird geöffnet und zum lokalen Repository navigiert.\n  Der Befehl git cherry-pick  wird ausgeführt, wobei  durch die tatsächliche Commit-ID ersetzt wird. Dadurch wird der ausgewählte Commit in den aktuellen Branch übernommen.\n  Es ist auch möglich, nur bestimmte Änderungen aus einem Commit oder einem Branch zu übernehmen, ohne den gesamten Commit oder Branch zu übernehmen. Eine Möglichkeit besteht darin, git cherry-pick mit der Option -n (oder \u0026ndash;no-commit) sowie git reset und git checkout zu verwenden:\n  Zunächst muss wieder sichergestellt werden, dass man sich auf dem gewünschten Ziel-Branch befindet, in den die Änderungen übernommen werden sollen. Um den aktuellen Branch im Terminal zu überprüfen, kann der Befehl git branch verwendet werden. Der aktuelle Branch wird dabei mit einem Sternchen (*) gekennzeichnet.\n  Sollte der aktuelle Branch nicht der gewünschte Ziel-Branch sein, kann man mit dem Befehl git checkout  auf den richtigen Branch wechseln, wobei  durch den tatsächlichen Namen des gewünschten Ziel-Branches ersetzt wird.\n  Die Commit-ID des gewünschten Commits muss gefunden werden. Dies kann durch das Durchsuchen der Commit-Historie in GitHub Desktop oder auf der GitHub-Webseite erfolgen.\n  Der Befehl git cherry-pick -n  wird ausgeführt, wobei  durch die tatsächliche Commit-ID ersetzt wird. Dadurch werden die Änderungen aus dem ausgewählten Commit in den aktuellen Branch übernommen, aber noch nicht committet.\n  Mit git checkout HEAD  können nun gezielt Änderungen aus bestimmten Dateien rückgängig gemacht werden, wobei  durch den tatsächlichen Dateinamen ersetzt wird. Dies entfernt die unerwünschten Änderungen aus dem Arbeitsverzeichnis und lässt nur die gewünschten Änderungen übrig.\n  Schließlich kann git add  verwendet werden, um die gewünschten Änderungen zum Commit vorzumerken, und git commit -m \u0026ldquo;\u0026rdquo; zum Erstellen eines neuen Commits mit diesen Änderungen, wobei  durch den tatsächlichen Dateinamen und  durch eine aussagekräftige Commit-Nachricht ersetzt wird.\n  Blaming Die Git-Blame-Funktion ermöglicht es, herauszufinden, wer eine bestimmte Änderung in einer Datei vorgenommen hat. Dies kann nützlich sein, um die Verantwortung für bestimmte Änderungen oder Entscheidungen im Text nachzuvollziehen. Die folgenden Schritte beschreiben, wie Blaming verwendet wird:\n  Auf der GitHub-Webseite navigiert man zum gewünschten Repository und öffnet die betreffende Datei.\n  Klickt man auf die Schaltfläche \u0026ldquo;Blame\u0026rdquo; (zu finden oben rechts in der Dateiansicht), wird eine Ansicht angezeigt, in der jede Zeile der Datei mit dem entsprechenden Autor und Commit gekennzeichnet ist.\n  In dieser Ansicht kann man nachverfolgen, wer welche Änderung vorgenommen hat und wann dies geschah. Bei Bedarf kann man auf den Commit-Link klicken, um weitere Informationen zum Commit und dessen Kontext zu erhalten.\n  Dieser Prozess stellt sicher, dass alle Änderungen sorgfältig überprüft werden und hilft, Konflikte und Fehler zu vermeiden.\n  ab hier wird mit Quarto beides gemeint, solange nicht anders angemerkt\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Geht auch mit Gitlab, hier wird aber keine Action zur Erstellung von Issues angeboten, was das Kommentieren von Manuskripten etwas anders gestaltet\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1678147200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"81c619fe83ea276d17cef89ba83b805d","permalink":"https://max-bre.de/blog/academic_collaboration_using_markdown_github/","publishdate":"2023-03-07T00:00:00Z","relpermalink":"/blog/academic_collaboration_using_markdown_github/","section":"blog","summary":"git und die darauf basierenden Hosting-Services Github und Gitlab sind Tools zur Versionskontrolle, die im Entwicklungskontext den De-Facto Industriestandard darstellen. Der Grund für diesen Erfolg ist dabei die Baum-artige Struktur in der Änderungen am Code-Stamm getracked und nachvollzogen werden können.","tags":["Quarto","R","Academia"],"title":"Akademisches Schreiben mit Github und Quarto","type":"blog"},{"authors":["Martina Oldeweme","Udo Konradt","Max Brede"],"categories":null,"content":"","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"aa0c7578cab27e42d78ed2e76c1697ee","permalink":"https://max-bre.de/publication/2023_oldeweme_therhythmof/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/publication/2023_oldeweme_therhythmof/","section":"publication","summary":"Objective: The recurring phase model of team processes suggests the existence of a rhythm of team task accomplishment, which refers to a repeated sequence of transition and action phases over time. Drawing on this model, we provide the first empirical investigation of whether different types of teamwork rhythm emerge, whether the rhythm varies according to the type of task, and whether the rhythm is related to team performance. Method: We observed and videoed student teams (N = 48) working on two different tasks (a creative task and a construction task) in a laboratory setting. Team processes were coded and assigned to transition or action phases using a custom algorithm. The rhythm of teamwork for each team was determined using the four parameters of tempo, regularity of tempo, focus (transition vs. action), and variability of focus. Results: Latent profile analysis revealed three distinct rhythms of teamwork across both tasks: a slow and action-oriented rhythm, a fast and regular rhythm, and a changing-focus rhythm. The results also show that the majority of the teams (63.04%) changed rhythm type between the tasks. Moreover, for the creative task, a changing-focus rhythm was predictive of lower performance (g = 0.25–0.48), whereas for the construction task, no association was found between rhythm and performance. Conclusions: The study provides a methodological procedure for analyzing the rhythm of teamwork and offers some initial insights into the types of teamwork rhythms and their association with type of tasks and levels of performance.","tags":null,"title":"The rhythm of teamwork: Discovering a complex temporal pattern of team processes.","type":"publication"},{"authors":null,"categories":null,"content":" Eine App zur Sammlung von Zitaten auf Crossref und Open Citations.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1669161600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"d2f7d92285a3c692aa509cd1d134dac8","permalink":"https://max-bre.de/shiny/crossref/","publishdate":"2022-11-23T00:00:00Z","relpermalink":"/shiny/crossref/","section":"shiny","summary":"Eine App zur Sammlung von Zitaten auf Crossref und Open Citations.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.","tags":["R","Shiny","Programmieren","Zitationen"],"title":"Crossref-Citations","type":"shiny"},{"authors":null,"categories":null,"content":" Eine Anleitung für mich selbst, wie meine Nextcloud aufgesetzt wurde.\nInstallation des Headless-Images nach der Pi-Installations-Anleitung.\nSetzen der Fallback-Static-IP:\nsudo apt install dhspcd5 sudo nano /etc/dhcpcd.conf Automatischer Shutdown um 22:00 Uhr:\nsudo crontab -e 00 22 * * * sudo shutdown System updaten:\nsudo apt-get update sudo apt-get upgrade Installation mit Docker und Docker-compose Festplatte auto-mounten:\nmkdir ~/nextcloud sudo nano /etc/fstab /dev/sda1 /home/pi/nextcloud ext4 defaults,noatime 0 2 Docker installieren und einrichten:\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh ./get-docker.sh sudo usermod -aG docker $USER sudo reboot Docker-Compose installieren:\nsudo apt get install docker-compose Damit Nextcloud gezogen werden kann musste man sich letztes mal bei Docker anmelden:\ndocker login Anschließend die docker-config so anpassen, dass es auf dem Pi funktioniert:\nnano ~/.docker/config.json Der Link im auth muss “https://index.docker.io/v1/” sein.\nDann die nötigen Ordner erstellen:\nmkdir nextcloud/nextcloud mkdir nextcloud/apps mkdir nextcloud/config mkdir nextcloud/data mkdir nextcloud/mariadb Und dann das docker-compose.yml wie in der Doku des offiziellen Nextcloud-Containers erstellen:\nversion: \u0026#39;2\u0026#39; volumes: nextcloud:~/nextcloud db:~/nextcloud/mariadb services: db: image: mariadb:10.6 restart: always command: --transaction-isolation=READ-COMMITTED --log-bin=binlog --binlog-format=ROW volumes: - db:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD= - MYSQL_PASSWORD= - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud app: image: nextcloud restart: always ports: - 8080:80 links: - db volumes: - nextcloud/nextcloud:/var/www/html - nextcloud/apps:/var/www/html/custom_apps - nextcloud/config:/var/www/html/config - nextcloud/data:/var/www/html/data environment: - MYSQL_PASSWORD= - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_HOST=db Anschließend mit docker-compose up -dstarten und für das beste hoffen.\nMit IP:port kann dann das Admin-Passwort gesetzt werden.\nUm ssl mit lets encrypt einzurichten braucht es dieses nginx proxy automation repo. Die Installationsanleitung findet sich hier\nDamit der Nextcloud-Container eingebunden wird muss das environment um die folgenden Variablen ergänzt werden:\n - VIRTUAL_HOST=your.domain.com - LETSENCRYPT_HOST=your.domain.com - LETSENCRYPT_EMAIL=your.email@your.domain.com - NEXTCLOUD_TRUSTED_DOMAINS=your.domain.com networks: default: external: name: proxy Anschließend muss das https-Protokoll überschrieben werden laut diesem Repo.\nAbschließend muss vielleicht noch in config/config.php die Domäne als “trusted domain” eingetragen werden. Bosh - fertig.\n Installation mit install-skript von nextcloudpi Nextcloud-Installation nach Anleitung:\ncurl -sSL https://raw.githubusercontent.com/nextcloud/nextcloudpi/master/install.sh | sudo bash Wichtig! Zuerst init über Web-Präsenz(https://nextcloudpi.local/).\nBei Frage nach SQL-Nutzer: wegen SSH-Zugang muss Passwort für root gesetzt werden, dazu einfach mysql per sudo aufrufen und wie folgt Passwort setzen:\nuse nextcloud; ALTER USER \u0026#39;ncp\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;new_password\u0026#39;; FLUSH PRIVILEGES; exit Wenn nicht geklappt ncp-init:\nsudo ncp-config config init Dann hinzufügen der trusted domains.\nAnschließend ssl-Zertifikat beantragen. http-Zugang muss freigeschaltet werden.\nDann festlegen dass apache nach mysql startet:\nhttps://github.com/nextcloud/server/issues/22119\nsudo nano /lib/systemd/system/apache2@.service sudo nano /lib/systemd/system/apache2.service After=mysql.service network.target remote-fs.target nss-lookup.targe Abschließend noch data- und db-dir auf die Festplatte verschieben.\nHoffentlich läuft es dann.\n ","date":1653177600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"6331c730a97edfc5bffcadde34ed9a4f","permalink":"https://max-bre.de/blog/pi_nextcloud/","publishdate":"2022-05-22T00:00:00Z","relpermalink":"/blog/pi_nextcloud/","section":"blog","summary":"Eine Anleitung für mich selbst, wie meine Nextcloud aufgesetzt wurde.\nInstallation des Headless-Images nach der Pi-Installations-Anleitung.\nSetzen der Fallback-Static-IP:","tags":["Raspberry Pi","Nextcloud","Admin","Linux"],"title":"Nextcloud auf dem Raspi Pi","type":"blog"},{"authors":null,"categories":null,"content":" Als Einführung in die Datenanalyse mit R für Studierende mit ersten Statistikkenntnissen ist das Skript zu EDV I entstanden, das ich in der Lehre der Übung zur Computerunterstützten Datenanalyse genutzt habe. Die Veranstaltung beschäftigt sich mit den Rsten Schritten im Umgang mit der freien Programmiersprache R, hin zu vollständigen Deskriptiven Analysen inklusive Darstellungen mit ggplot und Aggregationen und Datenaufbereitungen mit den anderen tidyverse-Paketen. Diese Übung durfte ich in den Wintersemestern 16/17, 17/18, 18/19, 19/20, 20/21 und 21/22 planen und veranstalten.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"987028c50785d59444afa306f6c1d059","permalink":"https://max-bre.de/skripte/edvi/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/skripte/edvi/","section":"skripte","summary":"Als Einführung in die Datenanalyse mit R für Studierende mit ersten Statistikkenntnissen ist das Skript zu EDV I entstanden, das ich in der Lehre der Übung zur Computerunterstützten Datenanalyse genutzt habe.","tags":["R","Data Wrangling","Data Viz"],"title":"EDV I","type":"skripte"},{"authors":null,"categories":null,"content":" Aufbauend auf dem Skript zu EDV I beschäftigt sich das Skript zu EDV II mit der R-basierten Auswertung von Datensätzen mit inferenzstatistischen Methoden. Zwar wird noch knapp auf Interpretation und Motivation der Verfahren eingegangen, das Augenmerk liegt aber auf der praktischen Durchführung der Verfahren. Die dazugehörige Übung zu Computerunterstützen Datenanalyse II durfte ich in den Sommersemestern 17, 18, 19, 20, 21 und 22 planen und veranstalten.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"284afcada1d5e4ea683cccdc7f0a0330","permalink":"https://max-bre.de/skripte/edvii/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/skripte/edvii/","section":"skripte","summary":"Aufbauend auf dem Skript zu EDV I beschäftigt sich das Skript zu EDV II mit der R-basierten Auswertung von Datensätzen mit inferenzstatistischen Methoden.","tags":["R","Statistik"],"title":"EDV II","type":"skripte"},{"authors":null,"categories":null,"content":" Demos für einzelne Aspekte der EDV2 - Übung. Vor allem Beispiele zur Demonstration des Nutzens von qqplots, außerdem eine Demo der Auswirkung unterschiedlicher Quadratsummen im Fall der zweifaktoriellen Varianzanalyse.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"a41dcba9ef5c27cead42f12450daed10","permalink":"https://max-bre.de/shiny/edv2/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/shiny/edv2/","section":"shiny","summary":"Demos für einzelne Aspekte der EDV2 - Übung. Vor allem Beispiele zur Demonstration des Nutzens von qqplots, außerdem eine Demo der Auswirkung unterschiedlicher Quadratsummen im Fall der zweifaktoriellen Varianzanalyse.","tags":["R","Shiny","Programmieren","Statistik"],"title":"EDV2 - Demos","type":"shiny"},{"authors":null,"categories":null,"content":" Eine Demo zur Darstellung des Verhaltens des kritischen Wertes bei Verschiebung von Korrelations-Nullhypothesen. Mit dieser App kann einfach geguckt werden, wie sich p-Wert und kritischer Wert bei Anpassung von empirischer Korrelation, hypothetisierter Korrelation und Stichprobengröße verändern.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"1ae535e1269c721a8af641a6784198d8","permalink":"https://max-bre.de/shiny/korrelationshypothesen/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/shiny/korrelationshypothesen/","section":"shiny","summary":"Eine Demo zur Darstellung des Verhaltens des kritischen Wertes bei Verschiebung von Korrelations-Nullhypothesen. Mit dieser App kann einfach geguckt werden, wie sich p-Wert und kritischer Wert bei Anpassung von empirischer Korrelation, hypothetisierter Korrelation und Stichprobengröße verändern.","tags":["R","Shiny","Programmieren","Statistik"],"title":"Korrelationshypothesen","type":"shiny"},{"authors":null,"categories":null,"content":" Im Skript zu Programmierung in R und Experimentdesign in Psychopy geht es um das Schreiben eigener Funktionen und Programme in R und Design, Durchführung und Auswertung von (online-) Experimenten in psychopy. Das Ziel dieses Skriptes ist es, den Teilnehmenden der Seminare Forschungsorientierte Vertiefung: Forschungsmethoden und Psychologische Forschungsmethoden. Projektseminar I im WS 21/22 die Werkzeuge an die Hand zu geben, eigene Simulationsstudien durchzuführen und den Umgang mit statistischen Voraussetzungstests durch Anwender experimentell zu untersuchen.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"f9429d97943cc9cdb5a15adbdc708cf2","permalink":"https://max-bre.de/skripte/assumptions/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/skripte/assumptions/","section":"skripte","summary":"Im Skript zu Programmierung in R und Experimentdesign in Psychopy geht es um das Schreiben eigener Funktionen und Programme in R und Design, Durchführung und Auswertung von (online-) Experimenten in psychopy.","tags":["R","Data Wrangling","Programmieren","Experimentieren"],"title":"Programmieren in R | Experimente in Psychopy","type":"skripte"},{"authors":null,"categories":null,"content":" Eine sehr, sehr basale Demo zur Darstellung des Grundprinzips von Reinforcement Learning. Die App lässt einen “Roboter” einen Pfad zum Ziel lernen, indem in einem Koordinatensystem Felder mit Gewichten versehen werden, die bedeuten, wie hilfreich ein Weg zum Finden des Ziels war.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"e5e7e967a0d94d3e4ec4faf5982ff999","permalink":"https://max-bre.de/shiny/reinforcement/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/shiny/reinforcement/","section":"shiny","summary":"Eine sehr, sehr basale Demo zur Darstellung des Grundprinzips von Reinforcement Learning. Die App lässt einen “Roboter” einen Pfad zum Ziel lernen, indem in einem Koordinatensystem Felder mit Gewichten versehen werden, die bedeuten, wie hilfreich ein Weg zum Finden des Ziels war.","tags":["R","Shiny","Programmieren"],"title":"Reinforcement-Roboter","type":"shiny"},{"authors":null,"categories":null,"content":" Das Skript zur Versuchsplanung ist im Rahmen meiner Seminare zur Versuchsplanung an der CAU zu Kiel entstanden, die ich in den Semestern SS17 (2x), WS17/18 (5x), WS18/19 (5x), WS19/20 und WS20/21 an der CAU zu Kiel gegeben habe. Im auf Studienanfänger ausgelegten Skript geht es um alle Schritte zur Planung eines psychologischen Experiments.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"34ebecbfef5227aca41f9de780359c5f","permalink":"https://max-bre.de/skripte/vplan/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/skripte/vplan/","section":"skripte","summary":"Das Skript zur Versuchsplanung ist im Rahmen meiner Seminare zur Versuchsplanung an der CAU zu Kiel entstanden, die ich in den Semestern SS17 (2x), WS17/18 (5x), WS18/19 (5x), WS19/20 und WS20/21 an der CAU zu Kiel gegeben habe.","tags":["Experimentieren"],"title":"Versuchsplanung","type":"skripte"},{"authors":["Steffen Lemke","Max Brede","Sophie Rotgeri","Isabella Peters"],"categories":null,"content":"","date":1639785600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"4685c0471cc458975de9b7f5f8f76821","permalink":"https://max-bre.de/publication/2021_lemke_researcharticlespromoted/","publishdate":"2021-12-18T00:00:00Z","relpermalink":"/publication/2021_lemke_researcharticlespromoted/","section":"publication","summary":"AbstractIn order to be able to provide thorough and timely coverage on the most recent scientific research, science journalists frequently rely on embargoed information sent to them by publishers of scientific journals. In such embargo e-mails, publishers purposefully bring selected upcoming releases to the journalists’ attention a few days in advance of their publication. Little is known on how this early highlighting of certain research articles affects their later citations or altmetrics. We present an exploratory case study with the aim of assessing the effects of such promotion activities on scientific articles’ bibliometric and altmetric indicators. In a treatment–control design, we analyze citation counts and eight types of altmetrics of 715 articles published between 2016 and 2017 whose DOIs have been mentioned in embargo e-mails and compare these to articles from the same journal issues that have not been highlighted in embargo e-mails. Descriptive statistics and Mann–Whitney-U tests reveal significant advantages for promoted articles across all regarded metrics three to four years after their publication. Particularly large differences can be seen regarding numbers of mentions in mainstream media, in blogs, on Twitter, and on Facebook. Our findings suggest that scholarly publishers exert significant influence over which research articles will receive attention and visibility in various (social) media. Also, regarding utilizations of metrics for evaluative purposes, the observed effects of promotional activities on indicators might constitute a factor of undesirable influence that currently does not receive the amount of consideration in scientometric assessments that it should receive.","tags":null,"title":"Research articles promoted in embargo e-mails receive higher citations and altmetrics","type":"publication"},{"authors":["Steffen Lemke","Julian Sakmann","Max Brede","Isabella Peters"],"categories":null,"content":"","date":1625529600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"83774fc9c51e3bd0af12cb719a6a2182","permalink":"https://max-bre.de/publication/2021_lemke_exploringtherelationship/","publishdate":"2021-07-06T00:00:00Z","relpermalink":"/publication/2021_lemke_exploringtherelationship/","section":"publication","summary":"Several studies have found that mentions of research articles in public media can have substantial effects on the articles' later citation counts and altmetrics. However, little attention so far went into investigating the potential relationship between qualitative properties of press texts that promote research and the research's impact. In this research in progress, we set out to manually analyze and compare the press releases published on EurekAlert! to promote a sample of 120 research articles, 60 of which later performed remarkably well concerning selected article-level metrics, while the remaining 60 articles later performed comparatively poorly. As a preliminary result, qualitative differences could be found regarding the press releases' structure, linguistic accessibility and the existence of narratives. First applications of our in-development codebook suggest associations between press releases with poor structure or accessibility and promoted research articles' metrics performance. We conclude with indications towards numerous promising paths for continuations of this study.","tags":null,"title":"Exploring the Relationship between Qualities of Press Releases to Research Articles and the Articles' Impact","type":"publication"},{"authors":null,"categories":null,"content":" Dieses Skript ist im Rahmen eines R-Crashkurses am KfN entstanden und ist darauf ausgelegt, Statistik-Anwendern die schon Erfahrungen mit anderen Statistik-Programmen und Base-R haben, die Vorteile der Auswertung mit dem tidyverse nahezubringen und einen Abriss über die üblichen Schritte zu geben.\nDieses Skript hat keinen Anspruch auf Vollständigkeit, es geht nur um einen Einstieg in die Auswertung mit R als Alternative zu anderen Software-Paketen.\n Sollte die Darstellung nicht richtig funktionieren, kann das Skript auch hier gefunden werden.\n","date":1607644800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"e7d467814ecc5c38620a5d6717e410b7","permalink":"https://max-bre.de/skripte/crash/","publishdate":"2020-12-11T00:00:00Z","relpermalink":"/skripte/crash/","section":"skripte","summary":"Dieses Skript ist im Rahmen eines R-Crashkurses am KfN entstanden und ist darauf ausgelegt, Statistik-Anwendern die schon Erfahrungen mit anderen Statistik-Programmen und Base-R haben, die Vorteile der Auswertung mit dem tidyverse nahezubringen und einen Abriss über die üblichen Schritte zu geben.","tags":["R","Data Wrangling","Data Viz","Statistik"],"title":"R Crashkurs","type":"skripte"},{"authors":null,"categories":null,"content":"Datenschutzerklärung Einleitung Mit der folgenden Datenschutzerklärung möchten wir Sie darüber aufklären, welche Arten Ihrer personenbezogenen Daten (nachfolgend auch kurz als \u0026ldquo;Daten“ bezeichnet) wir zu welchen Zwecken und in welchem Umfang verarbeiten. Die Datenschutzerklärung gilt für alle von uns durchgeführten Verarbeitungen personenbezogener Daten, sowohl im Rahmen der Erbringung unserer Leistungen als auch insbesondere auf unseren Webseiten, in mobilen Applikationen sowie innerhalb externer Onlinepräsenzen, wie z.B. unserer Social-Media-Profile (nachfolgend zusammenfassend bezeichnet als \u0026ldquo;Onlineangebot“). Die verwendeten Begriffe sind nicht geschlechtsspezifisch.\nInhaltsübersicht   Einleitung\n  Verantwortlicher\n  Übersicht der Verarbeitungen\n  Maßgebliche Rechtsgrundlagen\n  Sicherheitsmaßnahmen\n  Übermittlung und Offenbarung von personenbezogenen Daten\n  Datenverarbeitung in Drittländern\n  Bereitstellung des Onlineangebotes und Webhosting\n  Löschung von Daten\n  Änderung und Aktualisierung der Datenschutzerklärung\n  Rechte der betroffenen Personen\n  Begriffsdefinitionen\n  Verantwortlicher Brede, Max\nChristian-Albrechts-Universität zu Kiel\nOlshausenstraße 40\n24098 Kiel\nE-Mail-Adresse: contact[at]max-bre.de\nÜbersicht der Verarbeitungen Die nachfolgende Übersicht fasst die Arten der verarbeiteten Daten und die Zwecke ihrer Verarbeitung zusammen und verweist auf die betroffenen Personen.\nArten der verarbeiteten Daten  Inhaltsdaten (z.B. Eingaben in Onlineformularen). Meta-/Kommunikationsdaten (z.B. Geräte-Informationen, IP-Adressen). Nutzungsdaten (z.B. besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten).  Kategorien betroffener Personen  Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).  Zwecke der Verarbeitung  Erbringung vertragliche Leistungen und Kundenservice.  Maßgebliche Rechtsgrundlagen Im Folgenden teilen wir die Rechtsgrundlagen der Datenschutzgrundverordnung (DSGVO), auf deren Basis wir die personenbezogenen Daten verarbeiten, mit. Bitte beachten Sie, dass zusätzlich zu den Regelungen der DSGVO die nationalen Datenschutzvorgaben in Ihrem bzw. unserem Wohn- und Sitzland gelten können. Sollten ferner im Einzelfall speziellere Rechtsgrundlagen maßgeblich sein, teilen wir Ihnen diese in der Datenschutzerklärung mit.  Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f. DSGVO) - Die Verarbeitung ist zur Wahrung der berechtigten Interessen des Verantwortlichen oder eines Dritten erforderlich, sofern nicht die Interessen oder Grundrechte und Grundfreiheiten der betroffenen Person, die den Schutz personenbezogener Daten erfordern, überwiegen.  Sicherheitsmaßnahmen Wir treffen nach Maßgabe der gesetzlichen Vorgaben unter Berücksichtigung des Stands der Technik, der Implementierungskosten und der Art, des Umfangs, der Umstände und der Zwecke der Verarbeitung sowie der unterschiedlichen Eintrittswahrscheinlichkeiten und des Ausmaßes der Bedrohung der Rechte und Freiheiten natürlicher Personen geeignete technische und organisatorische Maßnahmen, um ein dem Risiko angemessenes Schutzniveau zu gewährleisten. Zu den Maßnahmen gehören insbesondere die Sicherung der Vertraulichkeit, Integrität und Verfügbarkeit von Daten durch Kontrolle des physischen und elektronischen Zugangs zu den Daten als auch des sie betreffenden Zugriffs, der Eingabe, der Weitergabe, der Sicherung der Verfügbarkeit und ihrer Trennung. Des Weiteren haben wir Verfahren eingerichtet, die eine Wahrnehmung von Betroffenenrechten, die Löschung von Daten und Reaktionen auf die Gefährdung der Daten gewährleisten. Ferner berücksichtigen wir den Schutz personenbezogener Daten bereits bei der Entwicklung bzw. Auswahl von Hardware, Software sowie Verfahren entsprechend dem Prinzip des Datenschutzes, durch Technikgestaltung und durch datenschutzfreundliche Voreinstellungen. Übermittlung und Offenbarung von personenbezogenen Daten Im Rahmen unserer Verarbeitung von personenbezogenen Daten kommt es vor, dass die Daten an andere Stellen, Unternehmen, rechtlich selbstständige Organisationseinheiten oder Personen übermittelt oder sie ihnen gegenüber offengelegt werden. Zu den Empfängern dieser Daten können z.B. Zahlungsinstitute im Rahmen von Zahlungsvorgängen, mit IT-Aufgaben beauftragte Dienstleister oder Anbieter von Diensten und Inhalten, die in eine Webseite eingebunden werden, gehören. In solchen Fall beachten wir die gesetzlichen Vorgaben und schließen insbesondere entsprechende Verträge bzw. Vereinbarungen, die dem Schutz Ihrer Daten dienen, mit den Empfängern Ihrer Daten ab. Datenverarbeitung in Drittländern Sofern wir Daten in einem Drittland (d.h., außerhalb der Europäischen Union (EU), des Europäischen Wirtschaftsraums (EWR)) verarbeiten oder die Verarbeitung im Rahmen der Inanspruchnahme von Diensten Dritter oder der Offenlegung bzw. Übermittlung von Daten an andere Personen, Stellen oder Unternehmen stattfindet, erfolgt dies nur im Einklang mit den gesetzlichen Vorgaben. Vorbehaltlich ausdrücklicher Einwilligung oder vertraglich oder gesetzlich erforderlicher Übermittlung verarbeiten oder lassen wir die Daten nur in Drittländern mit einem anerkannten Datenschutzniveau, vertraglichen Verpflichtung durch sogenannte Standardschutzklauseln der EU-Kommission, beim Vorliegen von Zertifizierungen oder verbindlicher internen Datenschutzvorschriften verarbeiten (Art. 44 bis 49 DSGVO, Informationsseite der EU-Kommission: https://ec.europa.eu/info/law/law-topic/data-protection/international-dimension-data-protection_de ). Bereitstellung des Onlineangebotes und Webhosting Um unser Onlineangebot sicher und effizient bereitstellen zu können, nehmen wir die Leistungen von einem oder mehreren Webhosting-Anbietern in Anspruch, von deren Servern (bzw. von ihnen verwalteten Servern) das Onlineangebot abgerufen werden kann. Zu diesen Zwecken können wir Infrastruktur- und Plattformdienstleistungen, Rechenkapazität, Speicherplatz und Datenbankdienste sowie Sicherheitsleistungen und technische Wartungsleistungen in Anspruch nehmen. Zu den im Rahmen der Bereitstellung des Hostingangebotes verarbeiteten Daten können alle die Nutzer unseres Onlineangebotes betreffenden Angaben gehören, die im Rahmen der Nutzung und der Kommunikation anfallen. Hierzu gehören regelmäßig die IP-Adresse, die notwendig ist, um die Inhalte von Onlineangeboten an Browser ausliefern zu können, und alle innerhalb unseres Onlineangebotes oder von Webseiten getätigten Eingaben. E-Mail-Versand und -Hosting: Die von uns in Anspruch genommenen Webhosting-Leistungen umfassen ebenfalls den Versand, den Empfang sowie die Speicherung von E-Mails. Zu diesen Zwecken werden die Adressen der Empfänger sowie Absender als auch weitere Informationen betreffend den E-Mailversand (z.B. die beteiligten Provider) sowie die Inhalte der jeweiligen E-Mails verarbeitet. Die vorgenannten Daten können ferner zu Zwecken der Erkennung von SPAM verarbeitet werden. Wir bitten darum, zu beachten, dass E-Mails im Internet grundsätzlich nicht verschlüsselt versendet werden. Im Regelfall werden E-Mails zwar auf dem Transportweg verschlüsselt, aber (sofern kein sogenanntes Ende-zu-Ende-Verschlüsselungsverfahren eingesetzt wird) nicht auf den Servern, von denen sie abgesendet und empfangen werden. Wir können daher für den Übertragungsweg der E-Mails zwischen dem Absender und dem Empfang auf unserem Server keine Verantwortung übernehmen.\nErhebung von Zugriffsdaten und Logfiles: Wir selbst (bzw. unser Webhostinganbieter) erheben Daten zu jedem Zugriff auf den Server (sogenannte Serverlogfiles). Zu den Serverlogfiles können die Adresse und Name der abgerufenen Webseiten und Dateien, Datum und Uhrzeit des Abrufs, übertragene Datenmengen, Meldung über erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite) und im Regelfall IP-Adressen und der anfragende Provider gehören. Die Serverlogfiles können zum einen zu Zwecken der Sicherheit eingesetzt werden, z.B., um eine Überlastung der Server zu vermeiden (insbesondere im Fall von missbräuchlichen Angriffen, sogenannten DDoS-Attacken) und zum anderen, um die Auslastung der Server und ihre Stabilität sicherzustellen.\n  Verarbeitete Datenarten: Inhaltsdaten (z.B. Eingaben in Onlineformularen), Nutzungsdaten (z.B. besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten), Meta-/Kommunikationsdaten (z.B. Geräte-Informationen, IP-Adressen).\n  Betroffene Personen: Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).\n  Zwecke der Verarbeitung: Erbringung vertragliche Leistungen und Kundenservice.\n  Rechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f. DSGVO).\n  Eingesetzte Dienste und Diensteanbieter:  WEB.DE Homepage \u0026amp; Mail: Hostingplattform für Websites; Dienstanbieter: 1\u0026amp;1 Mail \u0026amp; Media GmbH, Brauerstr. 48, 76135 Karlsruhe, Deutschland; Website: https://www.web.de; Datenschutzerklärung: https://agb-server.web.de/mdh-dsgvo.  Löschung von Daten Die von uns verarbeiteten Daten werden nach Maßgabe der gesetzlichen Vorgaben gelöscht, sobald deren zur Verarbeitung erlaubten Einwilligungen widerrufen werden oder sonstige Erlaubnisse entfallen (z.B., wenn der Zweck der Verarbeitung dieser Daten entfallen ist oder sie für den Zweck nicht erforderlich sind). Sofern die Daten nicht gelöscht werden, weil sie für andere und gesetzlich zulässige Zwecke erforderlich sind, wird deren Verarbeitung auf diese Zwecke beschränkt. D.h., die Daten werden gesperrt und nicht für andere Zwecke verarbeitet. Das gilt z.B. für Daten, die aus handels- oder steuerrechtlichen Gründen aufbewahrt werden müssen oder deren Speicherung zur Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen oder zum Schutz der Rechte einer anderen natürlichen oder juristischen Person erforderlich ist. Weitere Hinweise zu der Löschung von personenbezogenen Daten können ferner im Rahmen der einzelnen Datenschutzhinweise dieser Datenschutzerklärung erfolgen.\nÄnderung und Aktualisierung der Datenschutzerklärung Wir bitten Sie, sich regelmäßig über den Inhalt unserer Datenschutzerklärung zu informieren. Wir passen die Datenschutzerklärung an, sobald die Änderungen der von uns durchgeführten Datenverarbeitungen dies erforderlich machen. Wir informieren Sie, sobald durch die Änderungen eine Mitwirkungshandlung Ihrerseits (z.B. Einwilligung) oder eine sonstige individuelle Benachrichtigung erforderlich wird. Sofern wir in dieser Datenschutzerklärung Adressen und Kontaktinformationen von Unternehmen und Organisationen angeben, bitten wir zu beachten, dass die Adressen sich über die Zeit ändern können und bitten die Angaben vor Kontaktaufnahme zu prüfen. Rechte der betroffenen Personen Ihnen stehen als Betroffene nach der DSGVO verschiedene Rechte zu, die sich insbesondere aus Art. 15 bis 21 DSGVO ergeben:\n  Widerspruchsrecht: Sie haben das Recht, aus Gründen, die sich aus Ihrer besonderen Situation ergeben, jederzeit gegen die Verarbeitung der Sie betreffenden personenbezogenen Daten, die aufgrund von Art. 6 Abs. 1 lit. e oder f DSGVO erfolgt, Widerspruch einzulegen; dies gilt auch für ein auf diese Bestimmungen gestütztes Profiling. Werden die Sie betreffenden personenbezogenen Daten verarbeitet, um Direktwerbung zu betreiben, haben Sie das Recht, jederzeit Widerspruch gegen die Verarbeitung der Sie betreffenden personenbezogenen Daten zum Zwecke derartiger Werbung einzulegen; dies gilt auch für das Profiling, soweit es mit solcher Direktwerbung in Verbindung steht.\n  Widerrufsrecht bei Einwilligungen: Sie haben das Recht, erteilte Einwilligungen jederzeit zu widerrufen.\n  Auskunftsrecht: Sie haben das Recht, eine Bestätigung darüber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft über diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend den gesetzlichen Vorgaben.\n  Recht auf Berichtigung: Sie haben entsprechend den gesetzlichen Vorgaben das Recht, die Vervollständigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.\n  Recht auf Löschung und Einschränkung der Verarbeitung: Sie haben nach Maßgabe der gesetzlichen Vorgaben das Recht, zu verlangen, dass Sie betreffende Daten unverzüglich gelöscht werden, bzw. alternativ nach Maßgabe der gesetzlichen Vorgaben eine Einschränkung der Verarbeitung der Daten zu verlangen.\n  Recht auf Datenübertragbarkeit: Sie haben das Recht, Sie betreffende Daten, die Sie uns bereitgestellt haben, nach Maßgabe der gesetzlichen Vorgaben in einem strukturierten, gängigen und maschinenlesbaren Format zu erhalten oder deren Übermittlung an einen anderen Verantwortlichen zu fordern.\n  Beschwerde bei Aufsichtsbehörde: Sie haben ferner nach Maßgabe der gesetzlichen Vorgaben das Recht, bei einer Aufsichtsbehörde, insbesondere in dem Mitgliedstaat Ihres gewöhnlichen Aufenthaltsorts, Ihres Arbeitsplatzes oder des Orts des mutmaßlichen Verstoßes Beschwerde einzulegen, wenn Sie der Ansicht sind, dass die Verarbeitung der Sie betreffenden personenbezogenen Daten gegen die DSGVO verstößt.\n  Begriffsdefinitionen In diesem Abschnitt erhalten Sie eine Übersicht über die in dieser Datenschutzerklärung verwendeten Begrifflichkeiten. Viele der Begriffe sind dem Gesetz entnommen und vor allem im Art. 4 DSGVO definiert. Die gesetzlichen Definitionen sind verbindlich. Die nachfolgenden Erläuterungen sollen dagegen vor allem dem Verständnis dienen. Die Begriffe sind alphabetisch sortiert.\n  Personenbezogene Daten: \u0026ldquo;Personenbezogene Daten“ sind alle Informationen, die sich auf eine identifizierte oder identifizierbare natürliche Person (im Folgenden \u0026ldquo;betroffene Person“) beziehen; als identifizierbar wird eine natürliche Person angesehen, die direkt oder indirekt, insbesondere mittels Zuordnung zu einer Kennung wie einem Namen, zu einer Kennnummer, zu Standortdaten, zu einer Online-Kennung (z.B. Cookie) oder zu einem oder mehreren besonderen Merkmalen identifiziert werden kann, die Ausdruck der physischen, physiologischen, genetischen, psychischen, wirtschaftlichen, kulturellen oder sozialen Identität dieser natürlichen Person sind.\n  Verantwortlicher: Als \u0026ldquo;Verantwortlicher“ wird die natürliche oder juristische Person, Behörde, Einrichtung oder andere Stelle, die allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten entscheidet, bezeichnet.\n  Verarbeitung: \u0026ldquo;Verarbeitung\u0026rdquo; ist jeder mit oder ohne Hilfe automatisierter Verfahren ausgeführte Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten. Der Begriff reicht weit und umfasst praktisch jeden Umgang mit Daten, sei es das Erheben, das Auswerten, das Speichern, das Übermitteln oder das Löschen.\n  Vom Websiteinhaber angepasst. Erstellt mit kostenlosem Datenschutz-Generator.de von Dr. Thomas Schwenke\nImpressum Diensteanbieter Max Brede\nChristian-Albrechts-Universität zu Kiel\nOlshausenstraße 40\n24098 Kiel\nKontaktmöglichkeiten E-Mail-Adresse: contact[at]max-bre.de\nTelefon: +178$\\cdots$5501989\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1731257707,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://max-bre.de/privacy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/privacy/","section":"","summary":"Datenschutzerklärung Einleitung Mit der folgenden Datenschutzerklärung möchten wir Sie darüber aufklären, welche Arten Ihrer personenbezogenen Daten (nachfolgend auch kurz als \u0026ldquo;Daten“ bezeichnet) wir zu welchen Zwecken und in welchem Umfang verarbeiten.","tags":null,"title":"Impressum und Datenschutzerklärung","type":"page"}]